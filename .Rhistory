```{r, eval=FALSE}
webSource <- remDr$getPageSource()[[1]]
webSource
read_html(webSource)
html <- read_html(webSource)
html
html[2]
html[2]
links <- remDr$findElements("css", "article")
links
links[1]
links[1][1]
webElem <- remDr$findElement(using = "css", value = "a")
webElem$getElementAttribute("href")
View(t)
View(links)
webElem[2]$getElementAttribute("href")
webElem[3]$getElementAttribute("href")
webElem[44]$getElementAttribute("href")
webElem <- remDr$findElement(using = "css", value = "a")
webElem
webElem <- remDr$findElements(using = "css", value = "a")
webElem
webElem$getElementAttribute("href")
webElem[2]$getElementAttribute("href")
webElem[1]$getElementAttribute("href")
webElem
links <- remDr$findElements("css", "article")
webElem <- remDr$findElements(using = "css", value = "a")
sapply(webElem, function(x) x$getElementAttribute("href"))
apply(links, function(x) remDr$navigate(x))
apply(links, function(x) remDr$navigate(x))
remDr$navigate("https://www.nytimes.com/section/politics")
```{r, eval=FALSE}
webSource <- remDr$getPageSource()[[1]]
```
webElem <- remDr$findElements(using = "css", value = "a")
links <- sapply(webElem, function(x) x$getElementAttribute("href"))
apply(links, function(x) remDr$navigate(x))
links[1]
lapply(links, function(x) remDr$navigate(x))
remDr$navigate("https://www.nytimes.com/section/politics")
webSource <- remDr$getPageSource()[[1]]
```
links <- sapply(webElem, function(x) x$getElementAttribute("href"))
lapply(links, function(x) remDr$navigate(x))
html <- read_html("https://www.nytimes.com/live/2024/03/04/world/israel-hamas-war-gaza-news")
html
remDr$navigate("https://www.nytimes.com/live/2024/03/04/world/israel-hamas-war-gaza-news")
webSource <- remDr$getPageSource()[[1]]
webSource
```
webElem <- remDr$findElements(using = "class name", value = "stream-panel")
links <- sapply(webElem, function(x) x$getElementAttribute("href"))
links
webElem <- remDr$findElements(using = "class name", value = "stream-panel")
webElem
webElem <- remDr$findElements(using = c("class name"), "stream-panel")
links <- sapply(webElem, function(x) x$getElementAttribute("href"))
webElem
webElem <- remDr$findElements(using = c("id"), "stream-panel")
links <- sapply(webElem, function(x) x$getElementAttribute("href"))
webElem
links
webElem <- remDr$findElements(using = c("id"), "stream-panel")
links <- sapply(webElem, function(x) x$getElementAttribute("href"))
lapply(links, function(x) remDr$navigate(x))
web <- webElem$findElements("css", "a")
read_html(webElem)
webElem
webElem <- remDr$findElements("css", "ul")
webElem
links <- sapply(webElem, function(x) x$getElementAttribute("href"))
links
links[1]
links[1][1]
webElem <- remDr$findElement("css", "ul")
webElem
webs <- webElem %>% findElementsFromElement("css", "a")
links <- sapply(webElem, function(x) x$getElementAttribute("href"))
webElem$getElementText()
webElem <- remDr$findElement("id", "stream-panel")
webElem$getElementText()
webElem$findChildElements("css", "a")
webElem <- remDr$findElement("id", "stream-panel")
webs <- webElem$findChildElements("css", "a")
links <- sapply(webs, function(x) x$getElementAttribute("href"))
links
webElem <- remDr$findElement("id", "stream-panel")
webs <- webElem$findChildElements("css", "a")
links <- sapply(webs, function(x) x$getElementAttribute("href"))
links
```
# New York Times as of March, 2024 has their articles under the CSS navigation with the ID stream-panel
# Get the Articles from here
webElem <- remDr$findElement("id", "stream-panel")
# Articles contain the hyperlink to the article, save this element so we can iterate and get the hyperlinks
webs <- webElem$findChildElements("css", "a")
links <- sapply(webs, function(x) x$getElementAttribute("href"))
links
# Navigate to the NYT Politics, something very polarizing and more likely to Fake News
remDr$navigate("https://www.nytimes.com/section/politics")
# Scroll down the site
webElem <- remDr$findElement("css", "body")
for(x in 1:10) {
webElem$sendKeysToActiveElement(list(key = "Home"))
}
# Scroll down the site
webElem <- remDr$findElement("css", "body")
for(x in 1:10) {
webElem$sendKeysToActiveElement(list(key = "end"))
}
# Scroll down the site
webElem <- remDr$findElement("css", "body")
for(x in 1:10) {
webElem$sendKeysToElement(list(key = "end"))
}
# Get the WebSource of the Page
```{r, eval=FALSE}
webSource <- remDr$getPageSource()[[1]]
```
# New York Times as of March, 2024 has their articles under the CSS navigation with the ID stream-panel
# Get the Articles from here
webElem <- remDr$findElement("id", "stream-panel")
# Articles contain the hyperlink to the article, save this element so we can iterate and get the hyperlinks
webs <- webElem$findChildElements("css", "a")
links <- sapply(webs, function(x) x$getElementAttribute("href"))
links
# Go through each article and collect the articles
lapply(links, function(x) remDr$navigate(x))
remDr$navigate("https://www.nytimes.com/2024/03/04/us/politics/faa-boeing-737-max-audit.html")
webElem <- remDr$findElement("name", articleBody)
remDr$navigate("https://www.nytimes.com/2024/03/04/us/politics/faa-boeing-737-max-audit.html")
webElem <- remDr$findElement("name", articleBody)
webElem
webElem$getElementText
remDr$navigate("https://www.nytimes.com/2024/03/04/us/politics/faa-boeing-737-max-audit.html")
webElem <- remDr$findElement("name", "articleBody")
webElem$getElementText
webElem$findChildElements("css", "p")
sapply(webElem$findChildElements("css", "p"), function(x) x$getElementText)
webElem
sapply(webElem$findChildElements("css", "p"), function(x) x$getElementAttribute("p"))
sapply(webElem, function(x) x$getElementAttribute("p"))
sapply(webElem, function(x) x$getElementAttribute("p")
)
sapply(webElem, function(x) x$getElementAttribute("p"))
sapply(webElem, function(x) x$getElementAttribute("p"))
article <- sapply(webElem, function(x) x$getElementAttribute("p"))
paragraphs <- webElem$findChildElement("css", "p")
paragraphs
webElem <- remDr$findElement("name", "articleBody")
paragraphs <- webElem$findChildElement("css", "p")
remDr$navigate("https://www.nytimes.com/2024/03/04/us/politics/faa-boeing-737-max-audit.html")
webElem <- remDr$findElement("name", "articleBody")
paragraphs <- webElem$findChildElement("css", "p")
lapply(paragraphs, function(x) paragraphs$getElementText)
webElem <- remDr$findElement("name", "articleBody")
paragraphs <- webElem$findChildElements("css", "p")
lapply(paragraphs, function(x) paragraphs$getElementText)
paragraphs
webElem
webElem$getElementText
paragraphs <- webElem$findChildElements("css", "p")
lapply(paragraphs, function(x) x$getElementText)
webElem <- remDr$findElement("name", "articleBody")
paragraphs <- webElem$findChildElements("css", "p")
text <- lapply(paragraphs, function(x) x$getElementText)
text
text <- lapply(paragraphs, function(x) x$getElementAttribute("class"))
text
text <- lapply(paragraphs, function(x) x$getElementAttribute("class"))
text
text <- lapply(paragraphs, function(x) x$getElementValueOfCssProperty("p"))
text
text <- lapply(paragraphs, function(x) x$getElementText())
text
webElem <- remDr$findElement("name", "articleBody")
paragraphs <- webElem$findChildElements("css", "p")
text <- lapply(paragraphs, function(x) x$getElementText())
text
text[1]
paragraphs
paragraphs[[1]]
paragraphs[[1]]$getElementText
paragraphs[[1]]$getElementText()
paragraphs[[1]]$getActiveElement
paragraphs[[1]]$getActiveElement()
webElem
webElem$getElementText()
webElem
webElem$getElementAttributes("css", "p")
webElem$getElementAttribute("css", "p")
webElem$getElementAttributes("css", "p")
webElem$findChildElements("css", "p")
webElem$findElements("css", "p")
webElem$findChildElements("css", "p")
webElem$findElements("css", "p")
paragraphs <- webElem$findElements("css", "p")
text <- lapply(paragraphs, function(x) x$getElementText())
text
remDr$open()
remDr$navigate("https://www.nytimes.com/2024/03/04/us/politics/faa-boeing-737-max-audit.html")
# Setup the RSelenium to the ChromeDriver initializing the "server"
```{r, eval=FALSE}
rD <- RSelenium::rsDriver() # This might throw an error
remDr$navigate("https://www.nytimes.com/2024/03/04/us/politics/faa-boeing-737-max-audit.html")
remDr$navigate("https://www.nytimes.com/2024/03/04/us/politics/faa-boeing-737-max-audit.html")
webElem <- remDr$findElement("name", "articleBody")
# Assign the client to an object
remDr <- rD[["client"]]
remDr$navigate("https://www.nytimes.com/2024/03/04/us/politics/faa-boeing-737-max-audit.html")
webElem <- remDr$findElement("name", "articleBody")
paragraphs <- webElem$findElements("css", "p")
text <- lapply(paragraphs, function(x) x$getElementText())
text
paragraphs <- remDr$findElements("css", "p")
text <- lapply(paragraphs, function(x) x$getElementText())
text
text <- lapply(paragraphs, function(x) x[[1]]$getElementText())
text <- lapply(paragraphs, function(x) x[[0]]$getElementText())
text <- lapply(paragraphs, function(x) x[[0]]$getElementText())
paragraphs[[[1]]
paragraphs[[1]]
paragraphs[[1]]$getElementText()
paragraphs[[0]]
paragraphs[[1]]
webElem <- remDr$findElement("name", "articleBody")
paragraphs <- webElem$findChildElements("css", "p")
paragraphs[[1]]
paragraphs[[1]]$getElementText
paragraphs[[2]]$getElementText
paragraphs[[3]]$getElementText
paragraphs[[3]]$getElementText
paragraphs[[1]]$getElementText()
paragraphs[[1]][1]$getElementText()
paragraphs[[1]][[1]]$getElementText()
paragraphs <- remDr$findElements("css", "p")
paragraphs
length(paragraphs)
webElem$getElementAttribute("class")
paragraphs
paragraphs <- webElem$findElements("css", "p")
paragraphs
paragraphs[[1]]$getElementAttribute("class")
webElem <- remDr$findElement("name", "articleBody")
paragraphs <- webElem$findElements("css", "p")
text <- lapply(paragraphs, function(x) x[[0]]$getElementText())
paragraphs <- webElem$findElements("css", "p")
webElem <- remDr$findElement("name", "articleBody")
paragraphs <- webElem$findElements("css", "p")
paragraphs[[1]]$getElementText
paragraphs[[1]]$getElementText()
paragraphs[[1]]$getElementAttribute("class")
paragraphs <- webElem$findElements("css", "p")
paragraphs[[1]]$getElementAttribute("class")
paragraphs <- webElem$findChildElements("css", "p")
paragraphs[[1]]$getElementAttribute("class")
paragraphs[[1]]$getElementText()
paragraphs[[1]]$getElementAttribute("innerText")
text <- lapply(paragraphs, function(x) x$getElementText("innerText"))
webElem <- remDr$findElement("name", "articleBody")
paragraphs <- webElem$findChildElements("css", "p")
text <- lapply(paragraphs, function(x) x$getElementText("innerText"))
text <- lapply(paragraphs, function(x) x[[1]]$getElementText("innerText"))
text <- sapply(paragraphs, function(x) x$getElementText("innerText"))
text <- sapply(paragraphs, function(x) x$getElementAttribute("innerText"))
text
author <- remDr$findElement(using = c("css", "itemprop"), "span", "name")
author <- remDr$findElements(using = c("css", "itemprop"), "span")
author <- remDr$findElements(using = c("css"), "span")
summary <- remDr$findElements("id", "article-summary")
summary
summary$getElementText()
summaryy <- remDr$findElements("id", "article-summary")
summaryy[[1]]$getElementText()
summary <- remDr$findElement("id", "article-summary")$getElementText()
summary
title
title <- remDr$findElement("css", "h1")$getElementText()
title
title <- remDr$findElement("css", "h1")$getElementText()
author <- remDr$findElements(using = c("css", ""), "span")
summary <- remDr$findElement("id", "article-summary")$getElementText()
author <- remDr$findElement("class", "authorPageLinkClass overrideLinkStyles")
author <- remDr$findElement("class", "authorPageLinkClass")
author
author$getElementText
author$getElementText()
author$getElementAttribute("href")
author$getElementAttribute("innerText")
title <- remDr$findElement("css", "h1")$getElementText()
author <- remDr$findElement("class", "authorPageLinkClass")$getElementAttribute("innerText")
summary <- remDr$findElement("id", "article-summary")$getElementText()
title <- remDr$findElement("css", "h1")$getElementText()[[1]]
author <- remDr$findElement("class", "authorPageLinkClass")$getElementAttribute("innerText")[[1]]
summary <- remDr$findElement("id", "article-summary")$getElementText()[[1]]
title <- remDr$findElement("css", "h1")$getElementText()[[1]]
author <- remDr$findElement("class", "authorPageLinkClass")$getElementAttribute("innerText")[[1]]
summary <- remDr$findElement("id", "article-summary")$getElementText()[[1]]
webElem <- remDr$findElement("name", "articleBody")
paragraphs <- webElem$findChildElements("css", "p")
text <- sapply(paragraphs, function(x) x$getElementAttribute("innerText"))
titl
title
author
summary
text
paste(text)
t <- paste(text)
t
paragraphs <- webElem$findChildElements("css", "p")
text <- sapply(paragraphs, function(x) x$getElementAttribute("innerText"))
text <- paste(text)
text
str_c(text)
text[1]
text[2]
str_flatten(text)
str_flatten_comma(text)
text <- sapply(paragraphs, function(x) x$getElementAttribute("innerText"))
text <- str_flatten(text)
text
text <- sapply(paragraphs, function(x) x$getElementAttribute("innerText"))
text <- head(1, -1)
text <- str_flatten(text)
text
text <- head(x, -1)
text <- sapply(paragraphs, function(x) x$getElementAttribute("innerText"))
text <- head(x, -1)
text <- str_flatten(text)
text
text <- sapply(paragraphs, function(x) x$getElementAttribute("innerText"))
text <- str_flatten(text)
text
text <- sapply(paragraphs, function(x) x$getElementAttribute("innerText"))
text <- head(x1, -1)
text <- head(x, -1)
text <- str_flatten(text)
text <- head(x, -1)
text <- sapply(paragraphs, function(x) x$getElementAttribute("innerText"))
text
text[[4]]
head(text, -1)
text <- sapply(paragraphs, function(x) x$getElementAttribute("innerText"))
text <- head(text, -1)
text <- str_flatten(text)
text
library(dplyr)
library(stringr)
library(purrr)
library(rvest)
library(RSelenium)
# Setup the RSelenium to the ChromeDriver initializing the "server"
```{r, eval=FALSE}
rD <- RSelenium::rsDriver() # This might throw an error
```
# Assign the client to an object
remDr <- rD[["client"]]
# Navigate to the NYT Politics, something very polarizing and more likely to Fake News
remDr$navigate("https://www.nytimes.com/section/politics")
# Scroll down the site
webElem <- remDr$findElement("css", "body")
for(x in 1:10) {
webElem$sendKeysToElement(list(key = "end"))
}
# Get the WebSource of the Page
```{r, eval=FALSE}
webSource <- remDr$getPageSource()[[1]]
```
# New York Times as of March, 2024 has their articles under the CSS navigation with the ID stream-panel
# Get the Articles from here
webElem <- remDr$findElement("id", "stream-panel")
# Articles contain the hyperlink to the article, save this element so we can iterate and get the hyperlinks
webs <- webElem$findChildElements("css", "a")
links <- sapply(webs, function(x) x$getElementAttribute("href"))
remDr$navigate("https://www.nytimes.com/2024/03/04/us/politics/faa-boeing-737-max-audit.html")
title <- remDr$findElement("css", "h1")$getElementText()[[1]]
author <- remDr$findElement("class", "authorPageLinkClass")$getElementAttribute("innerText")[[1]]
summary <- remDr$findElement("id", "article-summary")$getElementText()[[1]]
webElem <- remDr$findElement("name", "articleBody")
paragraphs <- webElem$findChildElements("css", "p")
text <- sapply(paragraphs, function(x) x$getElementAttribute("innerText"))
text <- head(text, -1)
text <- str_flatten(text)
if (mysqlHasDefault()) {
con <- dbConnect(RMySQL::MySQL(), dbname = "Articles")
summary(con)
dbGetInfo(con)
dbListResults(con)
dbListTables(con)
dbDisconnect(con)
}
install.packages("RMySQL")
if (mysqlHasDefault()) {
con <- dbConnect(RMySQL::MySQL(), dbname = "Articles")
summary(con)
dbGetInfo(con)
dbListResults(con)
dbListTables(con)
dbDisconnect(con)
}
if (mysqlHasDefault()) {
con <- dbConnect(RMySQL::MySQL(), dbname = "Articles")
summary(con)
dbGetInfo(con)
dbListResults(con)
dbListTables(con)
dbDisconnect(con)
}
dbConnect(RMySQL::MySQL(), dbname = "Articles")
dbConnect(RMySQL::MySQL(), dbname = "Articles")
dbConnect(
drv,
dbname = "project",
username = "project",
password = "COMP541",
host = "150.230.44.118",
#unix.socket = NULL,
port = 3306,
#client.flag = 0,
#groups = "rs-dbi",
default.file = Database.R,
...
)
dbConnect(
drv,
dbname = "project",
username = "project",
password = "COMP541",
host = "150.230.44.118",
#unix.socket = NULL,
port = 3306,
#client.flag = 0,
#groups = "rs-dbi",
default.file = Database.R,
...
)
library(tm)
# Load the text data
library(RMySQL)
conn = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
texts = dbGetQuery(conn, statement = "select `text` from `Kaggle` where `X` = 3")
#texts <- c("Text one for analysis", "Another text for analysis")
removeSpecialChars <- function(x) {
gsub("[^a-zA-Z ]", "", x) # Keep only alphanumeric characters and spaces
}
# Create a corpus
corpus <- Corpus(VectorSource(texts))
# Preprocess the corpus: remove punctuation, numbers, whitespace, and convert to lowercase
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
corpus <- tm_map(corpus, stripWhitespace)
# Create a document-term matrix
dtm <- DocumentTermMatrix(corpus)
# Inspect the document-term matrix
inspect(dtm)
fullData = dbGetQuery(conn, statement = "select * from `Articles`")
fullData = dbGetQuery(conn, statement = "select * from `Articles` where `id` < 100")
# Create a corpus
corpus <- Corpus(VectorSource(fullData$text))
# Preprocess the corpus: remove punctuation, numbers, whitespace, and convert to lowercase
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
corpus <- tm_map(corpus, stripWhitespace)
# Create a document-term matrix
dtm <- DocumentTermMatrix(corpus)
# Inspect the document-term matrix
inspect(dtm)
dtm
library(tm)
# Load the text data
library(RMySQL)
conn = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
fullData = dbGetQuery(conn, statement = "select * from `Articles` where `id` < 100")
#func to remove everything but english characters and spaces
removeSpecialChars <- function(x) {
gsub("[^a-zA-Z ]", "", x)
}
# Create a corpus
corpus <- Corpus(VectorSource(fullData$text))
# clean the corpus
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
corpus <- tm_map(corpus, stripWhitespace)
install.packages("wordcloud2")
install.packages("wordcloud")
# Create a document-term matrix
tdm <- TermDocumentMatrix(corpus)
inspect(dtm)
m <- as.matrix(tdm)
v <- sort(rowSums(m), decreasing = TRUE)
d <- data.frame(word = names(v), freq = v)
wordcloud(d$word, d$freq, random.order=FALSE, rot.per=0)
library(tm)
library(wordcloud)
wordcloud(d$word, d$freq, random.order=FALSE, rot.per=0)
