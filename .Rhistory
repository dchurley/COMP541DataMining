train_data <- as.data.frame(as.matrix(spam))
labels <- data$label
# Train a Naive Bayes classifier
classifier <- naiveBayes(train_data, labels)
# Make predictions on new data
new_data <- "This is a new news article text to be classified."
new_corpus <- Corpus(VectorSource(new_data))
new_corpus <- tm_map(new_corpus, content_transformer(tolower))
new_corpus <- tm_map(new_corpus, removePunctuation)
new_corpus <- tm_map(new_corpus, removeNumbers)
new_corpus <- tm_map(new_corpus, removeWords, stopwords("english"))
new_dtm <- DocumentTermMatrix(new_corpus, list(dictionary = Terms(spam)))
new_spam <- removeSparseTerms(new_dtm, 0.999)
new_data <- as.data.frame(as.matrix(new_spam))
prediction <- predict(classifier, new_data)
# Print the prediction
print(prediction)
# Install required packages
#install.packages(c("tm", "e1071"))
# Load packages
library(tm)
library(e1071)
# Load the dataset (assuming it's a data frame with columns 'text' and 'label')
# Load your dataset (assuming it's in CSV format)
# Replace "your_dataset.csv" with the actual path to your dataset
library(RMySQL)
conn = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
data = dbGetQuery(conn, statement = "select * from `Kaggle`")
# Create a corpus from the text data
corpus <- Corpus(VectorSource(data$text))
# Perform text preprocessing (convert to lowercase, remove punctuation, numbers, and stopwords)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
# Create a document-term matrix
dtm <- DocumentTermMatrix(corpus)
# Convert the document-term matrix to a sparse matrix
spam <- removeSparseTerms(dtm, 0.999)
# Create data frames for training and labels
train_data <- as.data.frame(as.matrix(spam))
labels <- data$label
# Train a Naive Bayes classifier
classifier <- naiveBayes(train_data, labels)
# Install required packages
#install.packages(c("tm", "e1071"))
# Load packages
library(tm)
library(e1071)
# Load the dataset (assuming it's a data frame with columns 'text' and 'label')
# Load your dataset (assuming it's in CSV format)
# Replace "your_dataset.csv" with the actual path to your dataset
library(RMySQL)
conn = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
data = dbGetQuery(conn, statement = "select * from `Kaggle` where `X` < 1000")
# Create a corpus from the text data
corpus <- Corpus(VectorSource(data$text))
# Perform text preprocessing (convert to lowercase, remove punctuation, numbers, and stopwords)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
# Create a document-term matrix
dtm <- DocumentTermMatrix(corpus)
# Convert the document-term matrix to a sparse matrix
spam <- removeSparseTerms(dtm, 0.999)
# Create data frames for training and labels
train_data <- as.data.frame(as.matrix(spam))
labels <- data$label
# Train a Naive Bayes classifier
classifier <- naiveBayes(train_data, labels)
# Make predictions on new data
new_data <- "This is a new news article text to be classified."
new_corpus <- Corpus(VectorSource(new_data))
new_corpus <- tm_map(new_corpus, content_transformer(tolower))
new_corpus <- tm_map(new_corpus, removePunctuation)
new_corpus <- tm_map(new_corpus, removeNumbers)
new_corpus <- tm_map(new_corpus, removeWords, stopwords("english"))
new_dtm <- DocumentTermMatrix(new_corpus, list(dictionary = Terms(spam)))
new_spam <- removeSparseTerms(new_dtm, 0.999)
new_data <- as.data.frame(as.matrix(new_spam))
prediction <- predict(classifier, new_data)
# Print the prediction
print(prediction)
source("Database.R")
data <- SQL_GET_DATA("Articles", "`id` < 200")
removeSpecialChars <- function(x) {
gsub("[^a-zA-Z ]", "", x)
}
# Create a corpus from text data
corpus <- Corpus(VectorSource(data$text))
library(tidytext)
library(caret)
library(tm)
library(e1071)
removeSpecialChars <- function(x) {
gsub("[^a-zA-Z ]", "", x)
}
# Create a corpus from text data
corpus <- Corpus(VectorSource(data$text))
# clean the corpus
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
#remove the word said because it's the most common and it's boring
corpus <- tm_map(corpus, removeWords, "said")
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, stemDocument, language="english")
#creating term matrix with TF-IDF weighting
dtm <-DocumentTermMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
# Create a document-term matrix
#dtm <- DocumentTermMatrix(corpus)
dtm
spam <- removeSparseTerms(dtm, 0.98)
spam
spam <- removeSparseTerms(dtm, 0.98)
spam
spam <- removeSparseTerms(dtm, 0.99)
spam
spam <- removeSparseTerms(dtm, 0.9)
spam
spam <- removeSparseTerms(dtm, 0.8)
spam
print(spam)
print(as.data.frame(spam))
print(as.data.frame(as.matrix(spam)))
dataFrame <- as.data.frame(as.matrix(spam), stringsAsFactors=False)
dataFrame$label = data$label
dataFrame
dataFrame$label = data$label
dataFrame
dataFrame <- as.data.frame(as.matrix(spam), stringsAsFactors=False)
dataFrame <- as.data.frame(as.matrix(spam), stringsAsFactors=False)
dataFrame
dataFrame$label = data$label
data$label
source("Database.R")
data <- SQL_GET_DATA("Articles", "`id` < 200")
dataFrame$label = data$label
data$label
source("Database.R")
data <- SQL_GET_DATA("Kaggle", "`X` < 200")
data$id = data$X
removeSpecialChars <- function(x) {
gsub("[^a-zA-Z ]", "", x)
}
# Create a corpus from text data
corpus <- Corpus(VectorSource(data$text))
# clean the corpus
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
#remove the word said because it's the most common and it's boring
corpus <- tm_map(corpus, removeWords, "said")
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, stemDocument, language="english")
#creating term matrix with TF-IDF weighting
dtm <-DocumentTermMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
# Create a document-term matrix
#dtm <- DocumentTermMatrix(corpus)
dtm
spam <- removeSparseTerms(dtm, 0.8)
spam <- removeSparseTerms(dtm, 0.8)
spam
spam <- removeSparseTerms(dtm, 0.75)
spam
print(as.data.frame(as.matrix(spam)))
dataFrame <- as.data.frame(as.matrix(spam), stringsAsFactors=False)
dataFrame
dataFrame$label = data$label
dataFrame$label = data$label
dataFrame
install.packages("rpart")
library(rpart)
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dataFrame$label, p = .8,
list = FALSE,
times = 1)
library(rpart)
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dataFrame$label, p = .8,
list = FALSE,
times = 1)
library(tidytext)
library(caret)
library(tm)
library(e1071)
source("Database.R")
data <- SQL_GET_DATA("Kaggle", "`X` < 200")
data$id = data$X
removeSpecialChars <- function(x) {
gsub("[^a-zA-Z ]", "", x)
}
# Create a corpus from text data
corpus <- Corpus(VectorSource(data$text))
# clean the corpus
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
#remove the word said because it's the most common and it's boring
corpus <- tm_map(corpus, removeWords, "said")
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, stemDocument, language="english")
#creating term matrix with TF-IDF weighting
dtm <-DocumentTermMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
# Create a document-term matrix
#dtm <- DocumentTermMatrix(corpus)
spam <- removeSparseTerms(dtm, 0.75)
spam
print(as.data.frame(as.matrix(spam)))
dataFrame <- as.data.frame(as.matrix(spam), stringsAsFactors=False)
dataFrame
dataFrame$label = data$label
dataFrame
library(rpart)
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dataFrame$label, p = .8,
list = FALSE,
times = 1)
train_data <- dataFrame[trainIndex, ]
test_data <- dataFrame[-trainIndex, ]
# Train a classifier
model <- svm(label ~ ., data = train_data)
# Make predictions on test data
predictions <- predict(model, newdata = test_data)
# Evaluate the model
confusion_matrix <- table(predictions, test_data$label)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
confusion_matrix
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dataFrame$label, p = .8,
list = FALSE,
times = 1)
train_data <- dataFrame[trainIndex, ]
test_data <- dataFrame[-trainIndex, ]
# Train a classifier
model <- rpart(label ~ ., data = train_data)
# Make predictions on test data
predictions <- predict(model, newdata = test_data)
# Evaluate the model
confusion_matrix <- table(predictions, test_data$label)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
confusion_matrix
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dataFrame$label, p = .8,
list = FALSE,
times = 1)
train_data <- dataFrame[trainIndex, ]
test_data <- dataFrame[-trainIndex, ]
# Train a classifier
model <- rpart(label ~ ., data = train_data, type = "class")
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dataFrame$label, p = .8,
list = FALSE,
times = 1)
train_data <- dataFrame[trainIndex, ]
test_data <- dataFrame[-trainIndex, ]
# Train a classifier
model <- rpart(label ~ ., data = train_data, method = "class")
# Make predictions on test data
predictions <- predict(model, newdata = test_data)
# Evaluate the model
confusion_matrix <- table(predictions, test_data$label)
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dataFrame$label, p = .8,
list = FALSE,
times = 1)
train_data <- dataFrame[trainIndex, ]
test_data <- dataFrame[-trainIndex, ]
# Train a classifier
model <- rpart(label ~ ., data = train_data, method = "class")
# Make predictions on test data
predictions <- predict(model, newdata = test_data)
predictions
# Evaluate the model
confusion_matrix <- table(predictions, test_data$label)
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dataFrame$label, p = .8,
list = FALSE,
times = 1)
train_data <- dataFrame[trainIndex, ]
test_data <- dataFrame[-trainIndex, ]
# Train a classifier
model <- rpart(label ~ ., data = train_data, method = "class")
# Make predictions on test data
predictions <- predict(model, newdata = test_data, type = "class")
predictions
# Evaluate the model
confusion_matrix <- table(predictions, test_data$label)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
confusion_matrix
library(tidytext)
library(caret)
library(tm)
library(e1071)
source("Database.R")
data <- SQL_GET_DATA("Kaggle", "`X` < 200")
data$id = data$X
removeSpecialChars <- function(x) {
gsub("[^a-zA-Z ]", "", x)
}
# Create a corpus from text data
corpus <- Corpus(VectorSource(data$text))
# clean the corpus
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
#remove the word said because it's the most common and it's boring
corpus <- tm_map(corpus, removeWords, "said")
corpus <- tm_map(corpus, stripWhitespace)
#corpus <- tm_map(corpus, stemDocument, language="english")
#creating term matrix with TF-IDF weighting
dtm <-DocumentTermMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
# Create a document-term matrix
#dtm <- DocumentTermMatrix(corpus)
dtm
spam <- removeSparseTerms(dtm, 0.75)
spam
print(as.data.frame(as.matrix(spam)))
dataFrame <- as.data.frame(as.matrix(spam), stringsAsFactors=False)
dataFrame
dataFrame$label = data$label
dataFrame
library(rpart)
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dataFrame$label, p = .8,
list = FALSE,
times = 1)
train_data <- dataFrame[trainIndex, ]
test_data <- dataFrame[-trainIndex, ]
# Train a classifier
model <- rpart(label ~ ., data = train_data, method = "class")
# Make predictions on test data
predictions <- predict(model, newdata = test_data, type = "class")
predictions
# Evaluate the model
confusion_matrix <- table(predictions, test_data$label)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
confusion_matrix
library(RMySQL)
print("Hello")
mysqlconnection = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
dbListTables(mysqlconnection)
#result = dbSendQuery(mysqlconnection, "select * from Kaggle")
#data <- read.csv("COMP541Project/R/WELFake_Dataset.csv")
true_data <- read.csv("COMP541Project/R/True.csv")
#result = dbSendQuery(mysqlconnection, "select * from Kaggle")
#data <- read.csv("COMP541Project/R/WELFake_Dataset.csv")
true_data <- read.csv("R/True.csv")
fake_data <- read.csv("R/fake.csv")
library(RMySQL)
print("Hello")
mysqlconnection = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
dbListTables(mysqlconnection)
#result = dbSendQuery(mysqlconnection, "select * from Kaggle")
#data <- read.csv("COMP541Project/R/WELFake_Dataset.csv")
true_data <- read.csv("R/True.csv")
fake_data <- read.csv("R/fake.csv")
true_data$label = TRUE
fake_data$label = TRUE
head(data)
dbWriteTable(mysqlconnection, name = "Tutorial", value = true_data, row.names = FALSE, col.names = c("title", "text", "subject", "label"), overwrite = TRUE)
print(names(data))
library(RMySQL)
print("Hello")
mysqlconnection = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
dbListTables(mysqlconnection)
#result = dbSendQuery(mysqlconnection, "select * from Kaggle")
#data <- read.csv("COMP541Project/R/WELFake_Dataset.csv")
true_data <- read.csv("R/True.csv")
fake_data <- read.csv("R/fake.csv")
true_data$label = TRUE
fake_data$label = FALSE
head(data)
dbWriteTable(mysqlconnection, name = "Tutorial", value = fake_data, row.names = FALSE, col.names = c("title", "text", "subject", "label"), overwrite = TRUE)
print(names(data))
library(RMySQL)
print("Hello")
mysqlconnection = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
dbListTables(mysqlconnection)
#result = dbSendQuery(mysqlconnection, "select * from Kaggle")
#data <- read.csv("COMP541Project/R/WELFake_Dataset.csv")
true_data <- read.csv("R/True.csv")
fake_data <- read.csv("R/fake.csv")
true_data$label = TRUE
fake_data$label = FALSE
data <- rbind(true_data, fake_data)
# Assuming df is your data frame and you want to write columns "col1" and "col2" into a table named "target_table"
# Subset the columns of interest
data <- data[, c("title", "subject", "text", "label")]
# Write the subsetted data frame into the target table
# If the table already exists and you want to append the data, you can set append = TRUE
dbWriteTable(con, name = "Tutorial", value = data, append = TRUE)
library(RMySQL)
print("Hello")
conn = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
#result = dbSendQuery(mysqlconnection, "select * from Kaggle")
#data <- read.csv("COMP541Project/R/WELFake_Dataset.csv")
true_data <- read.csv("R/True.csv")
fake_data <- read.csv("R/fake.csv")
true_data$label = TRUE
fake_data$label = FALSE
data <- rbind(true_data, fake_data)
# Assuming df is your data frame and you want to write columns "col1" and "col2" into a table named "target_table"
# Subset the columns of interest
data <- data[, c("title", "subject", "text", "label")]
# Write the subsetted data frame into the target table
# If the table already exists and you want to append the data, you can set append = TRUE
dbWriteTable(conn, name = "Tutorial", value = data, append = TRUE)
# Write the subsetted data frame into the target table
# If the table already exists and you want to append the data, you can set append = TRUE
dbWriteTable(conn, name = "Tutorial", value = data, append = TRUE, row.names = FALSE)
head(data)
tail(data)
library(RMySQL)
print("Hello")
conn = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
#result = dbSendQuery(mysqlconnection, "select * from Kaggle")
#data <- read.csv("COMP541Project/R/WELFake_Dataset.csv")
true_data <- read.csv("R/True.csv")
fake_data <- read.csv("R/fake.csv")
true_data$label = 1
fake_data$label = 0
tail(data)
data <- rbind(true_data, fake_data)
tail(data)
head(data)
library(RMySQL)
print("Hello")
conn = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
#result = dbSendQuery(mysqlconnection, "select * from Kaggle")
#data <- read.csv("COMP541Project/R/WELFake_Dataset.csv")
true_data <- read.csv("R/True.csv")
fake_data <- read.csv("R/fake.csv")
true_data$label = 1
fake_data$label = 0
data <- rbind(true_data, fake_data)
# Assuming df is your data frame and you want to write columns "col1" and "col2" into a table named "target_table"
# Subset the columns of interest
data <- data[, c("title", "subject", "text", "label")]
# Write the subsetted data frame into the target table
# If the table already exists and you want to append the data, you can set append = TRUE
dbWriteTable(conn, name = "Tutorial", value = data, append = TRUE, row.names = FALSE)
# Close the database connection
dbDisconnect(con)
