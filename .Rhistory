dbSendQuery(mysqlconnection, paste('SET @title = "', title, '";'))
dbSendQuery(mysqlconnection, paste('SET @author = "', author, '";'))
dbSendQuery(mysqlconnection, paste('SET @summary = "', summary, '";'))
dbSendQuery(mysqlconnection, paste('SET @text = "', text, '";'))
dbSendQuery(mysqlconnection, paste('INSERT INTO', db_name, '(id, source, title, author, summary, text, rating)',
'VALUES(@ID, @source, @title, @author, @summary, @text, NULL)'))
result <- dbGetQuery(mysqlconnection, 'SELECT * FROM Articles WHERE ID = @id')
print(result)
id <- id + 1
}
id
fox_news_webscraper <- function(remDr, link) {
title <- NULL
author <- NULL
summary <- NULL
text <- NULL
print(link)
remDr$navigate(link)
Sys.sleep(2)
# Get Title
tryCatch({
title <- remDr$findElement("xpath", "/html[1]/body[1]/div[1]/div[1]/div[2]/div[1]/div[1]/article[1]/header[1]/h1[1]")
title <- title$getElementAttribute("innerText")
}, error = function(e) {
cat("Could not collect Title Information:", conditionMessage(e), "\n")
})
# Get Author
tryCatch({
author <- remDr$findElement("xpath", "/html[1]/body[1]/div[1]/div[1]/div[2]/div[1]/div[1]/article[1]/header[1]/div[3]/div[1]/span[1]/span[1]/a[1]")
author <- author$getElementAttribute("innerText")
}, error = function(e) {
cat("Could not collect Author Information:", conditionMessage(e), "\n")
})
tryCatch({
# Get Text
webElem <- remDr$findElement("xpath", "//body/div[@id='wrapper']/div[1]/div[2]/div[1]/div[1]/article[1]/div[1]/div[1]/div[1]")
text <- sapply(webElem$findChildElements("css", "p"), function(x){
x$getElementAttribute("innerText")
})
summary <- text[[1]]
}, error = function(e) {
cat("Could not collect Article Information:", conditionMessage(e), "\n")
})
# Get Summary & Cleanup Text
tryCatch({
for(paragraph in webElem$findChildElements("css", "p")[]) {
tryCatch({
webElem <- paragraph$findChildElement("css", "strong")
text <- (gsub(str_flatten(webElem$getElementAttribute("innerText")), '', text))
}, error = function(e) {cat()} )
}
}, error = function(e) {cat()})
text <- gsub('\"', '', str_flatten(text))
return(list(title, author, summary, text))
}
source("fox_news_webscraper.R")
source("fox_news_webscraper.R")
# Database input function
insert_into_database <- function(current_site, title, author, summary, text) {
# Do not insert data if text is null
if(is.null(text)) {
print("Warning: Could not insert into database, text is NULL.")
return()
}
id <- as.integer(dbGetQuery(mysqlconnection, "SELECT COUNT(*) FROM Articles") + 1)
# Send into database
dbSendQuery(mysqlconnection, paste('SET @ID = ', id, ";"))
dbSendQuery(mysqlconnection, paste('SET @source = "', current_site, '";'))
dbSendQuery(mysqlconnection, paste('SET @title = "', title, '";'))
dbSendQuery(mysqlconnection, paste('SET @author = "', author, '";'))
dbSendQuery(mysqlconnection, paste('SET @summary = "', summary, '";'))
dbSendQuery(mysqlconnection, paste('SET @text = "', text, '";'))
dbSendQuery(mysqlconnection, paste('INSERT INTO', db_name, '(id, source, title, author, summary, text, rating)',
'VALUES(@ID, @source, @title, @author, @summary, @text, NULL)'))
result <- dbGetQuery(mysqlconnection, 'SELECT * FROM Articles WHERE ID = @id')
print(result)
id <- id + 1
}
# FOX NEW WEBSCRAPER
current_site = "Fox News"
for(category in list("https://www.foxnews.com/category/politics/executive",
"https://www.foxnews.com/category/politics/senate",
"https://www.foxnews.com/category/politics/house-of-representatives",
"https://www.foxnews.com/category/politics/judiciary",
"https://www.foxnews.com/category/politics/foreign-policy")) {
links <- fox_news_linkscraper(remDr, category)
for(link in links) {
result <- fox_news_webscraper(remDr, link)
insert_into_database(current_site, result[[1]], result[[2]], result[[3]], result[[4]])
}
}
result[[2]]
result[[1]]
result[[1]]
result[[1]] <- gsub("'", "\'", result[[1]])
result[[1]]
result[[1]] <- gsub("‘", "\'", result[[1]])
result[[1]]
result[[1]] <- gsub("‘", "\\‘", result[[1]])
result[[1]]
result[[3]]
fox_news_linkscraper <- function(remDr, link) {
remDr$navigate(link)
webElem <- remDr$findElement("xpath", "//a[contains(text(),'Show More')]")
for(x in 1:10) {
webElem$clickElement()
Sys.sleep(1)
}
webElem <- remDr$findElement("xpath", "//body/div[@id='__nuxt']/div[@id='__layout']/div[@id='wrapper']/div[2]/div[3]/div[1]/main[1]/section[1]/div[1]")
links <- lapply(webElem$findChildElements("class", "article"), function(x) paste0(str_flatten(x$findChildElement("css", "a")$getElementAttribute("href")), ".amp"))
return(links)
}
result[[3]] <- gsub('\"', '', str_flatten(result[[3]]))
result[[3]]
insert_into_database(current_site, result[[1]], result[[2]], result[[3]], result[[4]])
dbSendQuery(mysqlconnection, "DELETE FROM Articles WHERE id > 397")
id
id <- as.integer(dbGetQuery(mysqlconnection, "SELECT COUNT(*) FROM Articles") + 1)
id
# FOX NEW WEBSCRAPER
current_site = "Fox News"
for(category in list("https://www.foxnews.com/category/politics/executive",
"https://www.foxnews.com/category/politics/senate",
"https://www.foxnews.com/category/politics/house-of-representatives",
"https://www.foxnews.com/category/politics/judiciary",
"https://www.foxnews.com/category/politics/foreign-policy")) {
links <- fox_news_linkscraper(remDr, category)
for(link in links) {
result <- fox_news_webscraper(remDr, link)
insert_into_database(current_site, result[[1]], result[[2]], result[[3]], result[[4]])
}
}
source("fox_news_webscraper.R")
# FOX NEW WEBSCRAPER
current_site = "Fox News"
for(category in list("https://www.foxnews.com/category/politics/executive",
"https://www.foxnews.com/category/politics/senate",
"https://www.foxnews.com/category/politics/house-of-representatives",
"https://www.foxnews.com/category/politics/judiciary",
"https://www.foxnews.com/category/politics/foreign-policy")) {
links <- fox_news_linkscraper(remDr, category)
for(link in links) {
result <- fox_news_webscraper(remDr, link)
insert_into_database(current_site, result[[1]], result[[2]], result[[3]], result[[4]])
}
}
id
id <- as.integer(dbGetQuery(mysqlconnection, "SELECT COUNT(*) FROM Articles") + 1)
id
links
library(rvest)
library(RSelenium)
library(RMySQL)
source("new_york_times_webscraper.R")
source("fox_news_webscraper.R")
# Setup database
mysqlconnection = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
dbListTables(mysqlconnection)
db_name <- "Articles"
# Database input function
insert_into_database <- function(current_site, title, author, summary, text) {
# Do not insert data if text is null
if(is.null(text)) {
print("Warning: Could not insert into database, text is NULL.")
return()
}
id <- as.integer(dbGetQuery(mysqlconnection, "SELECT COUNT(*) FROM Articles") + 1)
# Send into database
dbSendQuery(mysqlconnection, paste('SET @ID = ', id, ";"))
dbSendQuery(mysqlconnection, paste('SET @source = "', current_site, '";'))
dbSendQuery(mysqlconnection, paste('SET @title = "', title, '";'))
dbSendQuery(mysqlconnection, paste('SET @author = "', author, '";'))
dbSendQuery(mysqlconnection, paste('SET @summary = "', summary, '";'))
dbSendQuery(mysqlconnection, paste('SET @text = "', text, '";'))
dbSendQuery(mysqlconnection, paste('INSERT INTO', db_name, '(id, source, title, author, summary, text, rating)',
'VALUES(@ID, @source, @title, @author, @summary, @text, NULL)'))
result <- dbGetQuery(mysqlconnection, 'SELECT * FROM Articles WHERE ID = @id')
print(result)
id <- id + 1
}
# Setup the RSelenium to the ChromeDriver initializing the "server"
rD <- RSelenium::rsDriver() # This might throw an error
# Assign the client to an object
remDr <- rD[["client"]]
# NEW YORK TIMES WEB SCRAPER
current_site <- "New York Times"
links <- new_york_times_linkscraper("https://www.nytimes.com/section/politics")
library(dplyr)
library(stringr)
library(purrr)
# NEW YORK TIMES WEB SCRAPER
current_site <- "New York Times"
links <- new_york_times_linkscraper("https://www.nytimes.com/section/politics")
library(dplyr)
library(stringr)
library(purrr)
library(rvest)
library(RSelenium)
library(RMySQL)
source("new_york_times_webscraper.R")
source("fox_news_webscraper.R")
# Setup database
mysqlconnection = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
dbListTables(mysqlconnection)
db_name <- "Articles"
# Database input function
insert_into_database <- function(current_site, title, author, summary, text) {
# Do not insert data if text is null
if(is.null(text)) {
print("Warning: Could not insert into database, text is NULL.")
return()
}
id <- as.integer(dbGetQuery(mysqlconnection, "SELECT COUNT(*) FROM Articles") + 1)
# Send into database
dbSendQuery(mysqlconnection, paste('SET @ID = ', id, ";"))
dbSendQuery(mysqlconnection, paste('SET @source = "', current_site, '";'))
dbSendQuery(mysqlconnection, paste('SET @title = "', title, '";'))
dbSendQuery(mysqlconnection, paste('SET @author = "', author, '";'))
dbSendQuery(mysqlconnection, paste('SET @summary = "', summary, '";'))
dbSendQuery(mysqlconnection, paste('SET @text = "', text, '";'))
dbSendQuery(mysqlconnection, paste('INSERT INTO', db_name, '(id, source, title, author, summary, text, rating)',
'VALUES(@ID, @source, @title, @author, @summary, @text, NULL)'))
result <- dbGetQuery(mysqlconnection, 'SELECT * FROM Articles WHERE ID = @id')
print(result)
id <- id + 1
}
# Setup the RSelenium to the ChromeDriver initializing the "server"
rD <- RSelenium::rsDriver() # This might throw an error
# Assign the client to an object
remDr <- rD[["client"]]
# NEW YORK TIMES WEB SCRAPER
current_site <- "New York Times"
links <- new_york_times_linkscraper("https://www.nytimes.com/section/politics")
remDr$navigate("google.com")
links <- new_york_times_linkscraper("https://www.nytimes.com/section/politics")
source("new_york_times_webscraper.R")
source("fox_news_webscraper.R")
links <- new_york_times_linkscraper("https://www.nytimes.com/section/politics")
# FOX NEW WEBSCRAPER
current_site = "Fox News"
for(category in list("https://www.foxnews.com/category/politics/executive",
"https://www.foxnews.com/category/politics/senate",
"https://www.foxnews.com/category/politics/house-of-representatives",
"https://www.foxnews.com/category/politics/judiciary",
"https://www.foxnews.com/category/politics/foreign-policy")) {
links <- fox_news_linkscraper(remDr, category)
for(link in links) {
result <- fox_news_webscraper(remDr, link)
insert_into_database(current_site, result[[1]], result[[2]], result[[3]], result[[4]])
}
}
# Install necessary packages if not already installed
if (!require("caret")) install.packages("caret")
if (!require("tm")) install.packages("tm")
if (!require("e1071")) install.packages("e1071")
# Load required libraries
library(caret)
library(tm)
library(e1071)
# Load your dataset (assuming it's in CSV format)
# Replace "your_dataset.csv" with the actual path to your dataset
library(RMySQL)
conn = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
data = dbGetQuery(conn, statement = "select * from `Kaggle`")
head(data)
# Create a corpus from text data
corpus <- Corpus(VectorSource(data$text))
# Preprocess the text data
corpus <- tm_map(corpus, content_transformer(tolower))  # Convert to lowercase
corpus <- tm_map(corpus, removePunctuation)             # Remove punctuation
corpus <- tm_map(corpus, removeNumbers)                 # Remove numbers
corpus <- tm_map(corpus, removeWords, stopwords("en"))  # Remove stopwords
corpus <- tm_map(corpus, stripWhitespace)               # Strip whitespace
print("hello")
# Create a document-term matrix
dtm <- DocumentTermMatrix(corpus)
# Convert dtm to a matrix and then to a dataframe
dtm_matrix <- as.matrix(dtm)
data = dbGetQuery(conn, statement = "select * from `Kaggle`")
# Create a corpus from text data
corpus <- Corpus(VectorSource(data$text))
# clean the corpus
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
#remove the word said because it's the most common and it's boring
corpus <- tm_map(corpus, removeWords, "said")
corpus <- tm_map(corpus, stripWhitespace)
# Create a document-term matrix
dtm <- DocumentTermMatrix(corpus)
data = dbGetQuery(conn, statement = "select * from `Kaggle` where `X` < 30")
# Create a corpus from text data
corpus <- Corpus(VectorSource(data$text))
# clean the corpus
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
#remove the word said because it's the most common and it's boring
corpus <- tm_map(corpus, removeWords, "said")
corpus <- tm_map(corpus, stripWhitespace)
# Create a document-term matrix
dtm <- DocumentTermMatrix(corpus)
# Convert dtm to a matrix and then to a dataframe
dtm_matrix <- as.matrix(dtm)
dtm_df <- as.data.frame(dtm_matrix)
# Bind labels to the dataframe
dtm_df$label <- data$label
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dtm_df$label, p = .8,
list = FALSE,
times = 1)
train_data <- dtm_df[trainIndex, ]
test_data <- dtm_df[-trainIndex, ]
# Train a classifier
model <- svm(label ~ ., data = train_data)
# Install necessary packages if not already installed
if (!require("caret")) install.packages("caret")
if (!require("tm")) install.packages("tm")
if (!require("e1071")) install.packages("e1071")
# Load required libraries
library(caret)
library(tm)
library(e1071)
# Load your dataset (assuming it's in CSV format)
# Replace "your_dataset.csv" with the actual path to your dataset
library(RMySQL)
conn = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
data = dbGetQuery(conn, statement = "select * from `Kaggle` where `X` < 30")
# Create a corpus from text data
corpus <- Corpus(VectorSource(data$text))
# clean the corpus
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
# Install necessary packages if not already installed
if (!require("caret")) install.packages("caret")
if (!require("tm")) install.packages("tm")
if (!require("e1071")) install.packages("e1071")
# Load required libraries
library(caret)
library(tm)
library(e1071)
# Load your dataset (assuming it's in CSV format)
# Replace "your_dataset.csv" with the actual path to your dataset
library(RMySQL)
conn = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
data = dbGetQuery(conn, statement = "select * from `Kaggle` where `X` < 30")
removeSpecialChars <- function(x) {
gsub("[^a-zA-Z ]", "", x)
}
# Create a corpus from text data
corpus <- Corpus(VectorSource(data$text))
# clean the corpus
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
#remove the word said because it's the most common and it's boring
corpus <- tm_map(corpus, removeWords, "said")
corpus <- tm_map(corpus, stripWhitespace)
# Create a document-term matrix
dtm <- DocumentTermMatrix(corpus)
# Convert dtm to a matrix and then to a dataframe
dtm_matrix <- as.matrix(dtm)
dtm_df <- as.data.frame(dtm_matrix)
# Bind labels to the dataframe
dtm_df$label <- data$label
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dtm_df$label, p = .8,
list = FALSE,
times = 1)
train_data <- dtm_df[trainIndex, ]
test_data <- dtm_df[-trainIndex, ]
# Train a classifier
model <- svm(label ~ ., data = train_data)
# Make predictions on test data
predictions <- predict(model, newdata = test_data)
# Evaluate the model
confusion_matrix <- table(predictions, test_data$label)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
# Install necessary packages if not already installed
if (!require("caret")) install.packages("caret")
if (!require("tm")) install.packages("tm")
if (!require("e1071")) install.packages("e1071")
# Load required libraries
library(caret)
library(tm)
library(e1071)
# Load your dataset (assuming it's in CSV format)
# Replace "your_dataset.csv" with the actual path to your dataset
library(RMySQL)
conn = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
data = dbGetQuery(conn, statement = "select * from `Kaggle` where `X` < 100")
removeSpecialChars <- function(x) {
gsub("[^a-zA-Z ]", "", x)
}
# Create a corpus from text data
corpus <- Corpus(VectorSource(data$text))
# clean the corpus
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
#remove the word said because it's the most common and it's boring
corpus <- tm_map(corpus, removeWords, "said")
corpus <- tm_map(corpus, stripWhitespace)
# Create a document-term matrix
dtm <- DocumentTermMatrix(corpus)
# Convert dtm to a matrix and then to a dataframe
dtm_matrix <- as.matrix(dtm)
dtm_df <- as.data.frame(dtm_matrix)
# Bind labels to the dataframe
dtm_df$label <- data$label
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dtm_df$label, p = .8,
list = FALSE,
times = 1)
train_data <- dtm_df[trainIndex, ]
test_data <- dtm_df[-trainIndex, ]
# Train a classifier
model <- svm(label ~ ., data = train_data)
# Make predictions on test data
predictions <- predict(model, newdata = test_data)
# Evaluate the model
confusion_matrix <- table(predictions, test_data$label)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
# Install required libraries (if not already installed)
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("tidytext")) install.packages("tidytext")
# Load a sample fake news dataset (replace with your data source)
# Load your dataset (assuming it's in CSV format)
# Replace "your_dataset.csv" with the actual path to your dataset
library(RMySQL)
conn = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
data = dbGetQuery(conn, statement = "select * from `Kaggle` where `X` < 100")
# Preprocess text data
data <- data %>%
mutate(text = tolower(text)) %>%  # Convert to lowercase
mutate(text = gsub("[^[:alnum:]]", " ", text))  # Remove punctuation
# Feature Engineering - Example: Word count
data <- data %>%
mutate(word_count = str_word_count(text))
# Install required packages
install.packages(c("tm", "e1071"))
# Load packages
library(tm)
library(e1071)
# Load the dataset (assuming it's a data frame with columns 'text' and 'label')
# Load your dataset (assuming it's in CSV format)
# Replace "your_dataset.csv" with the actual path to your dataset
library(RMySQL)
conn = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
data = dbGetQuery(conn, statement = "select * from `Kaggle` where `X` < 100")
# Create a corpus from the text data
corpus <- Corpus(VectorSource(data$text))
# Perform text preprocessing (convert to lowercase, remove punctuation, numbers, and stopwords)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
# Create a document-term matrix
dtm <- DocumentTermMatrix(corpus)
