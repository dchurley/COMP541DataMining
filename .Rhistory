library(tm)
library(e1071)
source("Database.R")
data <- SQL_GET_DATA("Kaggle", "`X` < 200")
data$id = data$X
removeSpecialChars <- function(x) {
gsub("[^a-zA-Z ]", "", x)
}
# Create a corpus from text data
corpus <- Corpus(VectorSource(data$text))
# clean the corpus
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
#remove the word said because it's the most common and it's boring
corpus <- tm_map(corpus, removeWords, "said")
corpus <- tm_map(corpus, stripWhitespace)
#corpus <- tm_map(corpus, stemDocument, language="english")
#creating term matrix with TF-IDF weighting
dtm <-DocumentTermMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
# Create a document-term matrix
#dtm <- DocumentTermMatrix(corpus)
dtm
spam <- removeSparseTerms(dtm, 0.75)
spam
print(as.data.frame(as.matrix(spam)))
dataFrame <- as.data.frame(as.matrix(spam), stringsAsFactors=False)
dataFrame
dataFrame$label = data$label
dataFrame
library(rpart)
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dataFrame$label, p = .8,
list = FALSE,
times = 1)
train_data <- dataFrame[trainIndex, ]
test_data <- dataFrame[-trainIndex, ]
# Train a classifier
model <- rpart(label ~ ., data = train_data, method = "class")
# Make predictions on test data
predictions <- predict(model, newdata = test_data, type = "class")
predictions
# Evaluate the model
confusion_matrix <- table(predictions, test_data$label)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
confusion_matrix
library(RMySQL)
print("Hello")
mysqlconnection = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
dbListTables(mysqlconnection)
#result = dbSendQuery(mysqlconnection, "select * from Kaggle")
#data <- read.csv("COMP541Project/R/WELFake_Dataset.csv")
true_data <- read.csv("COMP541Project/R/True.csv")
#result = dbSendQuery(mysqlconnection, "select * from Kaggle")
#data <- read.csv("COMP541Project/R/WELFake_Dataset.csv")
true_data <- read.csv("R/True.csv")
fake_data <- read.csv("R/fake.csv")
library(RMySQL)
print("Hello")
mysqlconnection = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
dbListTables(mysqlconnection)
#result = dbSendQuery(mysqlconnection, "select * from Kaggle")
#data <- read.csv("COMP541Project/R/WELFake_Dataset.csv")
true_data <- read.csv("R/True.csv")
fake_data <- read.csv("R/fake.csv")
true_data$label = TRUE
fake_data$label = TRUE
head(data)
dbWriteTable(mysqlconnection, name = "Tutorial", value = true_data, row.names = FALSE, col.names = c("title", "text", "subject", "label"), overwrite = TRUE)
print(names(data))
library(RMySQL)
print("Hello")
mysqlconnection = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
dbListTables(mysqlconnection)
#result = dbSendQuery(mysqlconnection, "select * from Kaggle")
#data <- read.csv("COMP541Project/R/WELFake_Dataset.csv")
true_data <- read.csv("R/True.csv")
fake_data <- read.csv("R/fake.csv")
true_data$label = TRUE
fake_data$label = FALSE
head(data)
dbWriteTable(mysqlconnection, name = "Tutorial", value = fake_data, row.names = FALSE, col.names = c("title", "text", "subject", "label"), overwrite = TRUE)
print(names(data))
library(RMySQL)
print("Hello")
mysqlconnection = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
dbListTables(mysqlconnection)
#result = dbSendQuery(mysqlconnection, "select * from Kaggle")
#data <- read.csv("COMP541Project/R/WELFake_Dataset.csv")
true_data <- read.csv("R/True.csv")
fake_data <- read.csv("R/fake.csv")
true_data$label = TRUE
fake_data$label = FALSE
data <- rbind(true_data, fake_data)
# Assuming df is your data frame and you want to write columns "col1" and "col2" into a table named "target_table"
# Subset the columns of interest
data <- data[, c("title", "subject", "text", "label")]
# Write the subsetted data frame into the target table
# If the table already exists and you want to append the data, you can set append = TRUE
dbWriteTable(con, name = "Tutorial", value = data, append = TRUE)
library(RMySQL)
print("Hello")
conn = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
#result = dbSendQuery(mysqlconnection, "select * from Kaggle")
#data <- read.csv("COMP541Project/R/WELFake_Dataset.csv")
true_data <- read.csv("R/True.csv")
fake_data <- read.csv("R/fake.csv")
true_data$label = TRUE
fake_data$label = FALSE
data <- rbind(true_data, fake_data)
# Assuming df is your data frame and you want to write columns "col1" and "col2" into a table named "target_table"
# Subset the columns of interest
data <- data[, c("title", "subject", "text", "label")]
# Write the subsetted data frame into the target table
# If the table already exists and you want to append the data, you can set append = TRUE
dbWriteTable(conn, name = "Tutorial", value = data, append = TRUE)
# Write the subsetted data frame into the target table
# If the table already exists and you want to append the data, you can set append = TRUE
dbWriteTable(conn, name = "Tutorial", value = data, append = TRUE, row.names = FALSE)
head(data)
tail(data)
library(RMySQL)
print("Hello")
conn = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
#result = dbSendQuery(mysqlconnection, "select * from Kaggle")
#data <- read.csv("COMP541Project/R/WELFake_Dataset.csv")
true_data <- read.csv("R/True.csv")
fake_data <- read.csv("R/fake.csv")
true_data$label = 1
fake_data$label = 0
tail(data)
data <- rbind(true_data, fake_data)
tail(data)
head(data)
library(RMySQL)
print("Hello")
conn = dbConnect(RMySQL::MySQL(),
dbname='project',
host='150.230.44.118',
port=3306,
user='project',
password='COMP541',
local_infile = TRUE)
#result = dbSendQuery(mysqlconnection, "select * from Kaggle")
#data <- read.csv("COMP541Project/R/WELFake_Dataset.csv")
true_data <- read.csv("R/True.csv")
fake_data <- read.csv("R/fake.csv")
true_data$label = 1
fake_data$label = 0
data <- rbind(true_data, fake_data)
# Assuming df is your data frame and you want to write columns "col1" and "col2" into a table named "target_table"
# Subset the columns of interest
data <- data[, c("title", "subject", "text", "label")]
# Write the subsetted data frame into the target table
# If the table already exists and you want to append the data, you can set append = TRUE
dbWriteTable(conn, name = "Tutorial", value = data, append = TRUE, row.names = FALSE)
# Close the database connection
dbDisconnect(con)
library(tidytext)
library(caret)
library(tm)
library(e1071)
source("Database.R")
data <- SQL_GET_DATA("Tutorial")
data$id = data$X
removeSpecialChars <- function(x) {
gsub("[^a-zA-Z ]", "", x)
}
# Create a corpus from text data
corpus <- Corpus(VectorSource(data$text))
# clean the corpus
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
#remove the word said because it's the most common and it's boring
corpus <- tm_map(corpus, removeWords, "said")
corpus <- tm_map(corpus, stripWhitespace)
#corpus <- tm_map(corpus, stemDocument, language="english")
#creating term matrix with TF-IDF weighting
dtm <-DocumentTermMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
# Create a document-term matrix
#dtm <- DocumentTermMatrix(corpus)
dtm
spam <- removeSparseTerms(dtm, 0.75)
spam
print(as.data.frame(as.matrix(spam)))
dataFrame <- as.data.frame(as.matrix(spam), stringsAsFactors=False)
dataFrame
dataFrame$label = data$label
dataFrame
library(rpart)
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dataFrame$label, p = .8,
list = FALSE,
times = 1)
train_data <- dataFrame[trainIndex, ]
test_data <- dataFrame[-trainIndex, ]
# Train a classifier
model <- rpart(label ~ ., data = train_data, method = "class")
# Make predictions on test data
predictions <- predict(model, newdata = test_data, type = "class")
predictions
# Evaluate the model
confusion_matrix <- table(predictions, test_data$label)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
confusion_matrix
spam <- removeSparseTerms(dtm, 0.8)
spam
print(as.data.frame(as.matrix(spam)))
dataFrame <- as.data.frame(as.matrix(spam), stringsAsFactors=False)
dataFrame
dataFrame$label = data$label
dataFrame
library(rpart)
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dataFrame$label, p = .8,
list = FALSE,
times = 1)
train_data <- dataFrame[trainIndex, ]
test_data <- dataFrame[-trainIndex, ]
# Train a classifier
model <- rpart(label ~ ., data = train_data, method = "class")
# Make predictions on test data
predictions <- predict(model, newdata = test_data, type = "class")
# Evaluate the model
confusion_matrix <- table(predictions, test_data$label)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
confusion_matrix
confusion_matrix
library(tidytext)
library(caret)
library(tm)
library(e1071)
source("Database.R")
data <- SQL_GET_DATA("Tutorial")
data$id = data$X
removeSpecialChars <- function(x) {
gsub("[^a-zA-Z ]", "", x)
}
# Create a corpus from text data
corpus <- Corpus(VectorSource(data$text))
# clean the corpus
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
#remove the word said because it's the most common and it's boring
corpus <- tm_map(corpus, removeWords, c("said", "reuters"))
corpus <- tm_map(corpus, stripWhitespace)
#corpus <- tm_map(corpus, stemDocument, language="english")
#creating term matrix with TF-IDF weighting
dtm <-DocumentTermMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
# Create a document-term matrix
#dtm <- DocumentTermMatrix(corpus)
dtm
spam <- removeSparseTerms(dtm, 0.8)
spam
print(as.data.frame(as.matrix(spam)))
dataFrame <- as.data.frame(as.matrix(spam), stringsAsFactors=False)
dataFrame
dataFrame$label = data$label
dataFrame
library(rpart)
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dataFrame$label, p = .8,
list = FALSE,
times = 1)
train_data <- dataFrame[trainIndex, ]
test_data <- dataFrame[-trainIndex, ]
# Train a classifier
model <- rpart(label ~ ., data = train_data, method = "class")
# Make predictions on test data
predictions <- predict(model, newdata = test_data, type = "class")
# Evaluate the model
confusion_matrix <- table(predictions, test_data$label)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
confusion_matrix
spam <- removeSparseTerms(dtm, 0.95)
spam
spam <- removeSparseTerms(dtm, 0.90)
spam
dataFrame <- as.data.frame(as.matrix(spam), stringsAsFactors=False)
dataFrame$label = data$label
dataFrame
library(rpart)
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dataFrame$label, p = .8,
list = FALSE,
times = 1)
train_data <- dataFrame[trainIndex, ]
test_data <- dataFrame[-trainIndex, ]
# Train a classifier
model <- rpart(label ~ ., data = train_data, method = "class")
# Make predictions on test data
predictions <- predict(model, newdata = test_data, type = "class")
# Evaluate the model
confusion_matrix <- table(predictions, test_data$label)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
spam <- removeSparseTerms(dtm, 0.95)
spam
spam <- removeSparseTerms(dtm, 0.95)
spam
dataFrame <- as.data.frame(as.matrix(spam), stringsAsFactors=False)
dataFrame$label = data$label
dataFrame
library(rpart)
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dataFrame$label, p = .8,
list = FALSE,
times = 1)
train_data <- dataFrame[trainIndex, ]
test_data <- dataFrame[-trainIndex, ]
# Train a classifier
model <- rpart(label ~ ., data = train_data, method = "class")
# Make predictions on test data
predictions <- predict(model, newdata = test_data, type = "class")
# Evaluate the model
confusion_matrix <- table(predictions, test_data$label)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
confusion_matrix
row.names(dataFrame)
colnames(dataFrame)
word_list <- colnames(dataFrame)
words_to_remove <- c("label")
word_list <- word_list[!word_list %in% words_to_remove]
data <- SQL_GET_DATA("Kaggle")
data$id = data$X
corpus <- Corpus(VectorSource(data$text))
# clean the corpus
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
#remove the word said because it's the most common and it's boring
corpus <- tm_map(corpus, removeWords, c("said", "reuters"))
corpus <- tm_map(corpus, stripWhitespace)
#corpus <- tm_map(corpus, stemDocument, language="english")
#creating term matrix with TF-IDF weighting
dtm <-DocumentTermMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE), dictionary = word_list))
dataFrame <- as.data.frame(as.matrix(spam), stringsAsFactors=False)
dataFrame <- as.data.frame(as.matrix(dtm), stringsAsFactors=False)
dataFrame$label = data$label
dataFrame
# Make predictions on test data
predictions <- predict(model, newdata = dataFrame, type = "class")
# Evaluate the model
confusion_matrix <- table(predictions, dataFrame$label)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
# Make predictions on test data
predictions <- predict(model, newdata = dataFrame, type = "class")
# Evaluate the model
confusion_matrix <- table(predictions, dataFrame$label)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
confusion_matrix
kaggle$label[label==0] = 2
kaggle <- SQL_GET_DATA("Kaggle")
kaggle$label[label==0] = 2
word_list <- colnames(dataFrame)
words_to_remove <- c("label")
word_list <- word_list[!word_list %in% words_to_remove]
kaggle <- SQL_GET_DATA("Kaggle")
#invert the label column since the kaggle dataset uses 1 for fake and 0 for real
df$label <- ifelse(df$label == 0, 1, 0)
confusion_matrix
kaggle$label <- ifelse(kaggle$label == 0, 1, 0)
corpus <- Corpus(VectorSource(kaggle$text))
# clean the corpus
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
#remove the word said because it's the most common and it's boring
corpus <- tm_map(corpus, removeWords, c("said", "reuters"))
corpus <- tm_map(corpus, stripWhitespace)
#corpus <- tm_map(corpus, stemDocument, language="english")
#creating term matrix with TF-IDF weighting
dtm <-DocumentTermMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE), dictionary = word_list))
dataFrame <- as.data.frame(as.matrix(dtm), stringsAsFactors=False)
dataFrame$label = kaggle$label
dataFrame
# Make predictions on test data
predictions <- predict(model, newdata = dataFrame, type = "class")
# Evaluate the model
confusion_matrix <- table(predictions, dataFrame$label)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
confusion_matrix
gc()
#import libraries
library(tidytext)
library(caret)
library(tm)
library(e1071)
#get the training data
source("Database.R")
data <- SQL_GET_DATA("Tutorial")
data$id = data$X
#func to remove all characters but english alphabet letters
removeSpecialChars <- function(x) {
gsub("[^a-zA-Z ]", "", x)
}
# Create a corpus from text data
corpus <- Corpus(VectorSource(data$text))
# clean the corpus
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
#remove the word said because it's the most common and it's boring
corpus <- tm_map(corpus, removeWords, c("said", "reuters"))
corpus <- tm_map(corpus, stripWhitespace)
#corpus <- tm_map(corpus, stemDocument, language="english")
#creating term matrix with TF-IDF weighting
dtm <-DocumentTermMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE)))
# Create a document-term matrix
#dtm <- DocumentTermMatrix(corpus)
dtm
spam <- removeSparseTerms(dtm, 0.90)
spam
dataFrame <- as.data.frame(as.matrix(spam), stringsAsFactors=False)
dataFrame$label = data$label
dataFrame
library(rpart)
# Split data into training and testing sets
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(dataFrame$label, p = .8,
list = FALSE,
times = 1)
train_data <- dataFrame[trainIndex, ]
test_data <- dataFrame[-trainIndex, ]
# Train a classifier
model <- rpart(label ~ ., data = train_data, method = "class")
# Make predictions on test data
predictions <- predict(model, newdata = test_data, type = "class")
# Evaluate the model
confusion_matrix <- table(predictions, test_data$label)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
confusion_matrix
word_list <- colnames(dataFrame)
words_to_remove <- c("label")
word_list <- word_list[!word_list %in% words_to_remove]
kaggle <- SQL_GET_DATA("Kaggle")
#invert the label column since the kaggle dataset uses 1 for fake and 0 for real
kaggle$label <- ifelse(kaggle$label == 0, 1, 0)
corpus <- Corpus(VectorSource(kaggle$text))
# clean the corpus
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
#remove the word said because it's the most common and it's boring
corpus <- tm_map(corpus, removeWords, c("said", "reuters"))
corpus <- tm_map(corpus, stripWhitespace)
#corpus <- tm_map(corpus, stemDocument, language="english")
#creating term matrix with TF-IDF weighting
dtm <-DocumentTermMatrix(corpus,control = list(weighting = function(x) weightTfIdf(x, normalize = FALSE), dictionary = word_list))
dataFrame <- as.data.frame(as.matrix(dtm), stringsAsFactors=False)
dataFrame$label = kaggle$label
dataFrame
# Make predictions on test data
predictions <- predict(model, newdata = dataFrame, type = "class")
# Evaluate the model
confusion_matrix <- table(predictions, dataFrame$label)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
confusion_matrix
