```{r}
source("Database.R")

data <- SQL_GET_DATA("Tutorial")


data <- data[sample(nrow(data), 1000, replace = FALSE), ]

```

```{r}
library(syuzhet)
library(tm)
library(reshape2)
library(caret)
library(e1071)
library(rpart)
library(randomForest)
```


```{r}

corpus <- data$text

# Create a function to perform sentiment analysis on a single document
sentiment_analysis <- function(text) {
  # Preprocess text
  text <- tolower(text)
  text <- removePunctuation(text)
  text <- removeNumbers(text)
  
  # Tokenize the text
  tokens <- unlist(strsplit(text, "\\s+"))
  text <- paste(tokens, collapse = " ")
  
  # Perform sentiment analysis using syuzhet
  sentiment <- get_nrc_sentiment(text)
  
  return(sentiment)
}

# Apply sentiment analysis function to each document in the corpus
sentiment_scores <- lapply(data$text, sentiment_analysis)

# Convert the list of sentiment scores to a data frame
sentiment_df <- do.call(rbind, sentiment_scores)

# Add document IDs to the sentiment data frame
sentiment_df$id <- data$id

# Reshape the data frame to have documents as rows and sentiments as columns
sentiment_table <- dcast(melt(sentiment_df, id.vars = "id"), 
                         id ~ variable, value.var = "value", fill = 0)

# View the sentiment table


sentiment_table
df <- subset(sentiment_table, select = -id)

#df <- t(apply(df, 1, function(x) x / sum(x)))

df <- as.data.frame(df)
```


```{r}
df$label = data$label
df
```


```{r}
set.seed(123) # For reproducibility
trainIndex <- createDataPartition(df$label, p = .8, 
                                  list = FALSE, 
                                  times = 1)
train_data <- df[trainIndex, ]
test_data <- df[-trainIndex, ]

# Train a classifier
#model <- svm(label ~ ., data = train_data, method = "class")
model <- randomForest(label ~ ., data = train_data, method = "class")

```

```{r}
importance <- importance(model)

# Order the features by their importance
sorted_importance <- importance[order(importance[,1], decreasing = TRUE),]

# Display the top 10 features
top_10_features <- sorted_importance[1:10,]
print(top_10_features)
```


```{r}
train_data
```

```{r}
# Make predictions on test data
predictions <- predict(model, newdata = test_data, type= "class")
confusion_matrix <- table(predictions, test_data$label)
```

```{r}
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
confusion_matrix
```