```{r}
library(tm)
library(wordcloud)
library(topicmodels)
```

``` {r}
# Load the text data
library(RMySQL)
conn = dbConnect(RMySQL::MySQL(),
                            dbname='project',
                            host='150.230.44.118',
                            port=3306,
                            user='project',
                            password='COMP541',
                            local_infile = TRUE)

fullData = dbGetQuery(conn, statement = "select * from `Articles`")
```

```{r}
#func to remove everything but english characters and spaces
removeSpecialChars <- function(x) {
  gsub("[^a-zA-Z ]", "", x)
}

# Create a corpus
corpus <- Corpus(VectorSource(fullData$text))
# clean the corpus
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(removeSpecialChars))
corpus <- tm_map(corpus, removeWords, stopwords())
corpus <- tm_map(corpus, stripWhitespace)
```
```{r}
# TERM DOCUMENT matrix for word cloud
tdm <- TermDocumentMatrix(corpus)
m <- as.matrix(tdm)
v <- sort(rowSums(m), decreasing = TRUE)
d <- data.frame(word = names(v), freq = v)
```

```{r}
#this takes a long time to run
suppressWarnings(wordcloud(d$word, d$freq, random.order=FALSE, rot.per=0))
```
```{r}
#DOCUMENT TERM matrix for LDA
dtm <- DocumentTermMatrix(corpus)
# Filter out documents with no words
dtm <- dtm[rowSums(as.matrix(dtm)) > 0, ]
#dtm <- removeSparseTerms(dtm, sparse = 0.1)
```

```{r}
#this takes a minute to run
num_topics <- 5
lda_model <- LDA(dtm, k = num_topics, method = "Gibbs")
```

```{r}
# Get the terms associated with each topic
terms <- terms(lda_model, 10)  # Adjust the number of terms as needed

# Print the top terms for each topic
for (i in 1:num_topics) {
  cat("Topic", i, ":", paste(terms[i, ], collapse = ", "), "\n")
}
```
```{r}
# Get the topic distributions for each document
doc_topics <- posterior(lda_model)$topics

# Display the topic distribution for a specific document (e.g., document 1)
print(doc_topics[1, ])
```


